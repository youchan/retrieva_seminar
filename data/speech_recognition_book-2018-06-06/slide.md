# 第8章 音声の認識：言語モデル

イラストで学ぶ音声認識 2018/06/06 大崎 瑶

## もくじ

* 8.1 文法記述による言語モデル
* 8.2 統計的言語モデルの考え方
* 8.3 統計的言語モデルの作り方

## 言語モデル

![inline](p_w.png) を計算するためのモデル(![inline](w.png)は単語列)

* 文法規則によって入力を制限する方法
* 確率的言語モデルを用いて推定する方法

## 8.1 文法記述による言語モデル

* 規則に従う単語列であれば ![inline](p_w_gt_zero.png)
* そうでなければ ![inline](p_w_eq_zero.png)

## 正規文法(第4章)

1. ![inline](phi.png)(空集合)
2. すべての![inline](char.png)に対して![inline](chars.png)
3. ![inline](alpha_beta.png)が正規言語
  - 連接 ![inline](concat.png)
  - 選択 ![inline](select.png)
  - 繰り返し ![inline](repeat.png)

## 終端記号と非終端記号

![](regular.png)

a,ε => 終端記号 / A,B => 非終端記号

---

![](example.png)

その他の文脈自由文法でないものの例: プログラミング言語

## 統計的言語モデル

* 単語列 ![inline](word_list.png)
* 生成確率 ![inline](p_w.png)

![](total_score.png)

音響モデルで高いスコアを与えられたとしても、言語モデルで低いスコアの場合には総合的に低いスコアになる。(文法的に正しくないものはスコアが低くなる)

## Nグラム言語モデル

* 統計的言語モデル
  - P(W) = P(w1 ,...,wn) の値を言語統計から求める
  - 条件付き確率への展開
  - ![inline](eq1.png)
* N-グラム言語モデル
  - 長い履歴を持つ条件付き確率の値の推定は難しい
  - 履歴を、過去N-1単語で近似
  - ![inline2](eq2.png)

## 統計的言語モデルの作り方

1. コーパスを準備する
  - 大量の電子化された文章（新聞記事、webページなど）を集める
2. コーパスを単語に区切る
  - 形態素解析処理
3. 条件付き確率を求める
  - 確率の推定値が0にならないよう工夫したうえで P(wk | wk-N+1,...,wk-1) を求める

---

![](language_model.png)

## 出現しない単語に対する問題

* N-グラムを最尤推定するときの問題点
  - 例）2-グラムの単純な最尤推定
  - コーパス中に wi-1 wi が1度も出現しなければ、この値は0
  - 単語列中に値0の2-グラムが1つでもあれば、全体の確率が0
* バックオフスムージング
  - 最尤推定したN-グラムのうち、確率0でないものから少しずつ値を削り、確率0のものに分配する

---

